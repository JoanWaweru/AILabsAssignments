# -*- coding: utf-8 -*-
"""ANN_Scratch_ICS_Class.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1NqgoTA3GQRuAHLN6IDqyaVzSWJOUuAs_
"""

import pandas as pd 
import numpy as np

from numpy import array
from sklearn.preprocessing import Normalizer
from keras.activations import sigmoid
from keras.losses import mse
from numpy.random import uniform

"""Hyperparameters"""

batch_size=1

"""Dataset"""

data={'Day 1':[30,40,50,20,15,60],'Day 2':[40,50,20,15,60,70],
      'Day 3':[50,20,15,60,70,50],'Target':[20,15,60,70,50,40]}

dataset=pd.DataFrame(data)

dataset

X=dataset.drop('Target',axis=1)
y=dataset['Target']

X

X_norm = Normalizer(norm='max').fit_transform(X)

X_norm

array(y)

np.reshape(array(y),(1,-1))

y_norm=Normalizer(norm='max').fit_transform(np.reshape(array(y),(1,-1)))

y_norm

"""ANN From Scratch

**The 100 epocs**
"""

Epoc = 100
for x in range(Epoc):
  print( 'Epoc number:', x ,'\n')
  weight_1=array([[.2,.1],[.3,.1],[.2,.1]])
  weight_2=array([[.5],[.1]])
  weight_1=uniform(-1,1,(3,2)) #shape 3 by 2
  weight_2=uniform(-1,1,(2,1))
  output_1=X_norm[0:batch_size]@weight_1
  output_1
  act_output=sigmoid(output_1).numpy()
  act_output
  pred_output=act_output@weight_2
  pred_output=np.reshape(pred_output,(1,-1))
  pred_output
  y_true=y_norm[0][0:batch_size]
  y_pred=pred_output
  mse(y_true,y_pred).numpy()

  #Back Propagation

  y1 = y_true[0]
  y2 = y_pred
  output=y1-y2
  output2 = y2*(1-y2)
  error_k = output * output2

  #Error of hidden Layers ğ‘¬ğ’“ğ’“ğ’ğ’“(ğ’‹) = ğ’†ğ’“ğ’“ğ’ğ’“ ğ’‚ğ’• ğ’Œ âˆ— ğ’˜ğ’†ğ’Šğ’ˆğ’‰ğ’• ğ’ğ’‡ ğ’˜ğ’‹ğ’Œ âˆ— ğ’‡â€™(ğ’™ğ’‹)
  error_j = error_k * weight_2[0][0] * (act_output[0][0] * (1 - act_output[0][0]))
  error_i = error_k * weight_2[1][0] * (act_output[0][1] * (1 - act_output[0][1]))

  #Delta rule: ğ‘Šğ‘›ğ‘’ğ‘¤ = ğ‘Šğ‘ğ‘¢ğ‘Ÿğ‘Ÿğ‘’ğ‘›ğ‘¡ + Î”ğ‘Šğ‘ğ‘¢ğ‘Ÿğ‘Ÿğ‘’ğ‘›t
  n = uniform(0,1)
  w_new_j = weight_2[0][0] + (n * error_k * y_pred)
  w_new_j = np.reshape(array(w_new_i),(1,1))
  w_new_i = weight_2[1][0] + (n * error_k * y_pred)
  w_new_i = np.reshape(array(w_new_i),(1,1))
  weight_2_update = np.concatenate((w_new_j, w_new_i))
  print('weight_2_update\n')
  print(weight_2_update, '\n')

  #Calculating weights for the first layer
  weight_1_update = weight_1[:,0].reshape(-1,1) + (n * error_j * output_1[0][0])
  weight_1_update_cont = weight_1[:,1].reshape(-1,1) + (n * error_i * output_1[0][1])
  weight_1_update = np.concatenate((weight_1_update, weight_1_update_cont), axis=1)
  print('Weight_1_update\n')
  print(weight_1_update, '\n')

  #Uisng the updated weights
  output_1=X_norm[0:batch_size]@weight_1_update
  output_1
  act_output=sigmoid(output_1).numpy()
  act_output
  pred_output=act_output@weight_2_update
  pred_output=np.reshape(pred_output,(1,-1))
  print('Predicted output:\n')
  print(pred_output)
  y_true=y_norm[0][0:batch_size]
  print('Expected output:\n')
  print(y_true)
  y_pred=pred_output
  mse(y_true,y_pred).numpy()

"""Trials of the first epoc.

weight_1=array([[.2,.1],[.3,.1],[.2,.1]])
weight_2=array([[.5],[.1]])
"""

weight_1=uniform(-1,1,(3,2)) #shape 3 by 2
weight_2=uniform(-1,1,(2,1))

weight_1[:,0]

weight_2[0][0]

X_norm[0:batch_size]

output_1=X_norm[0:batch_size]@weight_1
output_1

act_output=sigmoid(output_1).numpy()
act_output

pred_output=act_output@weight_2
pred_output=np.reshape(pred_output,(1,-1))
pred_output

"""Mean Squared Error"""

y_true=y_norm[0][0:batch_size]
y_pred=pred_output

y_pred

y_true

mse(y_true,y_pred).numpy()

"""Back Propagation"""

y1 = y_true[0]
y1

y2 = y_pred
y2

output=y1-y2
output

"""Error Computation"""

output2 = y2*(1-y2)
output2

error_k = output * output2
error_k

"""Error of hidden Layers
ğ‘¬ğ’“ğ’“ğ’ğ’“(ğ’‹) = ğ’†ğ’“ğ’“ğ’ğ’“ ğ’‚ğ’• ğ’Œ âˆ— ğ’˜ğ’†ğ’Šğ’ˆğ’‰ğ’• ğ’ğ’‡ ğ’˜ğ’‹ğ’Œ âˆ— ğ’‡â€™(ğ’™ğ’‹)
"""

error_j = error_k * weight_2[0][0] * (act_output[0][0] * (1 - act_output[0][0]))
error_j

error_i = error_k * weight_2[1][0] * (act_output[0][1] * (1 - act_output[0][1]))
error_i

"""Delta rule: ğ‘Šğ‘›ğ‘’ğ‘¤ = ğ‘Šğ‘ğ‘¢ğ‘Ÿğ‘Ÿğ‘’ğ‘›ğ‘¡ + Î”ğ‘Šğ‘ğ‘¢ğ‘Ÿğ‘Ÿğ‘’ğ‘›t


"""

n = uniform(0,1)
n

w_new_j = weight_2[0][0] + (n * error_k * y_pred)
w_new_j = np.reshape(array(w_new_i),(1,1))
w_new_j

w_new_i = weight_2[1][0] + (n * error_k * y_pred)
w_new_i = np.reshape(array(w_new_i),(1,1))
w_new_i

weight_2_update = np.concatenate((w_new_j, w_new_i))
print('weight_2_update\n')
weight_2_update

weight_1

output_1

output_1[0][1]

weight_1

weight_1[:,0]

weight_1[:,0].reshape(-1,1)

"""Calculating weights for the first layer"""

weight_1_update = weight_1[:,0].reshape(-1,1) + (n * error_j * output_1[0][0])
weight_1_update_cont = weight_1[:,1].reshape(-1,1) + (n * error_i * output_1[0][1])
weight_1_update = np.concatenate((weight_1_update, weight_1_update_cont), axis=1)
print('Weight_1_update\n')
weight_1_update